# this object should have 5 fewer articles than the previous import
importSub <- import_results(file = "BibChunks/download1.bib", verbose = TRUE) %>%
# additional files for import go here, like for initial import above
# make sure NA's are NA's not strings (reads bib format funny)
mutate_all(~ replace(., .=='NA', NA)) %>%
# remove the articles already assessed from the original download
# sorting by title only to streamline the anti_join
anti_join(import, ., by = "title")
# this is the list of articles the next subset is made from
#Identifying papers that are NOT shared by Risely and the subset
import_results(file = "BibChunks/download1.bib", verbose = TRUE) %>%
anti_join(importRisely) %>% select(author, title)
# not re-run when creating next subset
set <- importSub[sample(nrow(importSub), 5),]
write_bibliography(set, "BibChunks/download2.bib", format = "bib")
# not re-run when creating next subset
set <- importSub2[sample(nrow(importSub2), 5),]
# this is re-run for every new subset
# replace #'s with subset number
importSub2 <- import_results(file = "BibChunks/download2.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub, ., by = "title") # add previous subset number
# not re-run when creating next subset
set <- importSub2[sample(nrow(importSub2), 5),]
write_bibliography(set, "BibChunks/download3.bib", format = "bib")
# this is re-run for every new subset
# replace #'s with subset number
importSub3 <- import_results(file = "BibChunks/download3.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub2, ., by = "title") # add previous subset number
# this is re-run for every new subset
# replace #'s with subset number
importSub4 <- import_results (file = "BibChunks/download4.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub3, ., by = "title") # add previous subset number
# this is re-run for every new subset
# replace #'s with subset number
importSub5 <- import_results (file = "BibChunks/download5.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub4, ., by = "title") # add previous subset number
# this is re-run for every new subset
# replace #'s with subset number
importSub6 <- import_results (file = "BibChunks/download6.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub5, ., by = "title") # add previous subset number
# this is re-run for every new subset
# replace #'s with subset number
importSub7 <- import_results (file = "BibChunks/download7.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub6, ., by = "title") # add previous subset number
# this is re-run for every new subset
# replace #'s with subset number
importSub8 <- import_results (file = "BibChunks/download8.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub7, ., by = "title") # add previous subset number
# this is re-run for every new subset
# replace #'s with subset number
importSub9 <- import_results (file = "BibChunks/download9.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub8, ., by = "title") # add previous subset number
# this is re-run for every new subset
# replace #'s with subset number
importSub10 <- import_results (file = "BibChunks/download10.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub9, ., by = "title") # add previous subset number
# this is re-run for every new subset
# replace #'s with subset number
importSub11 <- import_results (file = "BibChunks/download11.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub10, ., by = "title") # add previous subset number
download1.bib <- import_results(file = "BibChunks/download1.bib", verbose = TRUE)
View(download1.bib)
download9.bib <- import_results(file = "BibChunks/download9.bib", verbose = TRUE)
View(download9.bib)
#Identifying papers that are NOT shared by Risely and the subset
import_results(file = "BibChunks/download11.bib", verbose = TRUE) %>%
anti_join(importRisely) %>% select(author, title)
# not re-run when creating next subset
set <- importSub11[sample(nrow(importSub11), 5),]
write_bibliography(set, "BibChunks/download12.bib", format = "bib")
# this is re-run for every new subset
# replace #'s with subset number
importSub12 <- import_results (file = "BibChunks/download12.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub11, ., by = "title") # add previous subset number
#Identifying papers that are NOT shared by Risely and the subset
import_results(file = "BibChunks/download12.bib", verbose = TRUE) %>%
anti_join(importRisely) %>% select(author, title)
#Identifying papers that are NOT shared by Risely and the subset
import_results(file = "BibChunks/download12.bib", verbose = TRUE) %>%
anti_join(importRisely) %>% select(author, title)
# not re-run when creating next subset
set <- importSub12[sample(nrow(importSub12), 5),]
write_bibliography(set, "BibChunks/download13.bib", format = "bib")
# this is re-run for every new subset
# replace #'s with subset number
importSub13 <- import_results (file = "BibChunks/download13.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub12, ., by = "title") # add previous subset number
#Identifying papers that are NOT shared by Risely and the subset
import_results(file = "BibChunks/download13.bib", verbose = TRUE) %>%
anti_join(importRisely) %>% select(author, title)
#Identifying papers that are NOT shared by Risely and the subset
import_results(file = "BibChunks/download13.bib", verbose = TRUE) %>%
anti_join(importRisely) %>% select(author, title)
# not re-run when creating next subset
set <- importSub13[sample(nrow(importSub13), 5),]
write_bibliography(set, "BibChunks/download14.bib", format = "bib")
# this is re-run for every new subset
# replace #'s with subset number
importSub14 <- import_results (file = "BibChunks/download14.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub13, ., by = "title") # add previous subset number
#Identifying papers that are NOT shared by Risely and the subset
import_results(file = "BibChunks/download14.bib", verbose = TRUE) %>%
anti_join(importRisely) %>% select(author, title)
# not re-run when creating next subset
set <- importSub14[sample(nrow(importSub14), 5),]
write_bibliography(set, "BibChunks/download15.bib", format = "bib")
# this is re-run for every new subset
# replace #'s with subset number
importSub15 <- import_results (file = "BibChunks/download15.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub14, ., by = "title") # add previous subset number
#Identifying papers that are NOT shared by Risely and the subset
import_results(file = "BibChunks/download15.bib", verbose = TRUE) %>%
anti_join(importRisely) %>% select(author, title)
download11.bib <- import_results(file = "BibChunks/download11.bib", verbose = TRUE)
View(download11.bib)
download10.bib <- import_results(file = "BibChunks/download10.bib", verbose = TRUE)
View(download10.bib)
download12.bib <- import_results(file = "BibChunks/download12.bib", verbose = TRUE)
View(download12.bib)
download10.bib <- import_results(file = "BibChunks/download13.bib", verbose = TRUE)
View(download13.bib)
download14.bib <- import_results(file = "BibChunks/download14.bib", verbose = TRUE)
View(download14.bib)
download15.bib <- import_results(file = "BibChunks/download15.bib", verbose = TRUE)
View(download15.bib)
# not re-run when creating next subset
set <- importSub12[sample(nrow(importSub12), 5),]
write_bibliography(set, "BibChunks/download13.bib", format = "bib")
# this is re-run for every new subset
# replace #'s with subset number
importSub13 <- import_results (file = "BibChunks/download13.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub12, ., by = "title") # add previous subset number
#Identifying papers that are NOT shared by Risely and the subset
import_results(file = "BibChunks/download13.bib", verbose = TRUE) %>%
anti_join(importRisely) %>% select(author, title)
download10.bib <- import_results(file = "BibChunks/download13.bib", verbose = TRUE)
View(download13.bib)
# not re-run when creating next subset
set <- importSub12[sample(nrow(importSub12), 5),]
write_bibliography(set, "BibChunks/download13.bib", format = "bib")
# not re-run when creating next subset
set <- importSub12[sample(nrow(importSub12), 5),]
write_bibliography(set, "BibChunks/download13.bib", format = "bib")
# this is re-run for every new subset
# replace #'s with subset number
importSub13 <- import_results (file = "BibChunks/download13.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub12, ., by = "title") # add previous subset number
#Identifying papers that are NOT shared by Risely and the subset
import_results(file = "BibChunks/download13.bib", verbose = TRUE) %>%
anti_join(importRisely) %>% select(author, title)
# not re-run when creating next subset
set <- importSub12[sample(nrow(importSub12), 5),]
write_bibliography(set, "BibChunks/download13.bib", format = "bib")
# this is re-run for every new subset
# replace #'s with subset number
importSub13 <- import_results (file = "BibChunks/download13.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub12, ., by = "title") # add previous subset number
download10.bib <- import_results(file = "BibChunks/download13.bib", verbose = TRUE)
View(download13.bib)
download14.bib <- import_results(file = "BibChunks/download14.bib", verbose = TRUE)
View(download14.bib)
download13.bib <- import_results(file = "BibChunks/download13.bib", verbose = TRUE)
View(download13.bib)
download10.bib <- import_results(file = "BibChunks/download10.bib", verbose = TRUE)
View(download10.bib)
# not re-run when creating next subset
set <- importSub15[sample(nrow(importSub15), 5),]
write_bibliography(set, "BibChunks/download16.bib", format = "bib")
# this is re-run for every new subset
# replace #'s with subset number
importSub16 <- import_results (file = "BibChunks/download16.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub15, ., by = "title") # add previous subset number
#Identifying papers that are NOT shared by Risely and the subset
import_results(file = "BibChunks/download16.bib", verbose = TRUE) %>%
anti_join(importRisely) %>% select(author, title)
# not re-run when creating next subset
set <- importSub16[sample(nrow(importSub16), 5),]
write_bibliography(set, "BibChunks/download17.bib", format = "bib")
# this is re-run for every new subset
# replace #'s with subset number
importSub17 <- import_results (file = "BibChunks/download17.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub16, ., by = "title") # add previous subset number
#Identifying papers that are NOT shared by Risely and the subset
import_results(file = "BibChunks/download17.bib", verbose = TRUE) %>%
anti_join(importRisely) %>% select(author, title)
# not re-run when creating next subset
set <- importSub17[sample(nrow(importSub17), 5),]
write_bibliography(set, "BibChunks/download18.bib", format = "bib")
# this is re-run for every new subset
# replace #'s with subset number
importSub18 <- import_results (file = "BibChunks/download18.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub17, ., by = "title") # add previous subset number
#Identifying papers that are NOT shared by Risely and the subset
import_results(file = "BibChunks/download18.bib", verbose = TRUE) %>%
anti_join(importRisely) %>% select(author, title)
# not re-run when creating next subset
set <- importSub18[sample(nrow(importSub18), 5),]
write_bibliography(set, "BibChunks/download19.bib", format = "bib")
# this is re-run for every new subset
# replace #'s with subset number
importSub19 <- import_results (file = "BibChunks/download19.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub18, ., by = "title") # add previous subset number
#Identifying papers that are NOT shared by Risely and the subset
import_results(file = "BibChunks/download19.bib", verbose = TRUE) %>%
anti_join(importRisely) %>% select(author, title)
# not re-run when creating next subset
set <- importSub19[sample(nrow(importSub19), 5),]
write_bibliography(set, "BibChunks/download20.bib", format = "bib")
# this is re-run for every new subset
# replace #'s with subset number
importSub20 <- import_results (file = "BibChunks/download20.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSub19, ., by = "title") # add previous subset number
#Identifying papers that are NOT shared by Risely and the subset
import_results(file = "BibChunks/download20.bib", verbose = TRUE) %>%
anti_join(importRisely) %>% select(author, title)
download16.bib <- import_results(file = "BibChunks/download16.bib", verbose = TRUE)
View(download16.bib)
download17.bib <- import_results(file = "BibChunks/download17.bib", verbose = TRUE)
View(download17.bib)
download18.bib <- import_results(file = "BibChunks/download18.bib", verbose = TRUE)
View(download18.bib)
download19.bib <- import_results(file = "BibChunks/download19.bib", verbose = TRUE)
View(download19.bib)
download20.bib <- import_results(file = "BibChunks/download20.bib", verbose = TRUE)
View(download20.bib)
knitr::opts_chunk$set(echo = TRUE)
download9.bib <- import_results(file = "BibChunks/download9.bib", verbose = TRUE)
# run every time
# load required packages
library(litsearchr)
#install.packages("revtools")
library(revtools)
library(tidyverse)
# set working directory to file location
setwd("~/University/University 2020-2021/thesis/MicrobiomeThesis")
download9.bib <- import_results(file = "BibChunks/download9.bib", verbose = TRUE)
View(download9.bib)
knitr::opts_chunk$set(echo = TRUE)
# run every time
# load required packages
library(litsearchr)
#install.packages("revtools")
library(revtools)
library(tidyverse)
# set working directory to file location
setwd("~/University/University 2020-2021/thesis/MicrobiomeThesis")
# read the initial .RIS data into R
importRisely <- import_results(file = "ReferencesRisely.ris", verbose = TRUE)
import <- import_results(file = "ReferencesCompiled01.txt", verbose = TRUE) %>%
# join compiled references from R with Risely papers
full_join(importRisely)
download10.bib <- import_results(file = "BibChunks/download10.bib", verbose = TRUE)
View(download10.bib)
download11.bib <- import_results(file = "BibChunks/download11.bib", verbose = TRUE)
View(download11.bib)
library(readxl)
library(tidyverse)
library(car)
library(effects)
library(ggplot2)
install.packages("ggpubr")
library(ggpubr)
#load dataframe
Biol3010_Pipeline_Data <- read_excel("Biol3010_Pipeline_Data.xlsx")
View(Biol3010_Pipeline_Data)
#ANCOVA
pipeline_anc <- lm(species_richness~habitat_type + spatial_distance + species_abundance + spatial_distance*habitat_type, data = Biol3010_Pipeline_Data)
Anova(pipeline_anc, type=3)
summary(pipeline_anc)
#residuals
Biol3010_Pipeline_Data$predicted <- predict(pipeline_anc)# Save the predicted
Biol3010_Pipeline_Data$residuals <- residuals(pipeline_anc) # Save the residual values
#load dataframe
Biol3010_Pipeline_Data <- read_excel("Biol3010_Pipeline_Data.xlsx")
#load dataframe
Biol3010_Pipeline_Data <- read_excel("Biol3010_Pipeline_Data.xlsx")
View(Biol3010_Pipeline_Data)
Tadpoles=read.csv(file.choose("tadpoles.csv"))
View(Tadpoles)
str(Tadpoles)
attach(Tadpoles)
Mod1 <- lm(Rel.fit ~ RW1. + RW2. + RW3. + Centroid.size)
summary(Mod1)
knitr::opts_chunk$set(echo = TRUE)
# load required packages
library(easyPubMed)
library(revtools)
library(litsearchr)
library(tidyverse)
# write query based on searchterms and date parameter
CompiledData <- '(((microbial community) OR (bacterial community) OR (bacterial communities) OR (microbial communities) OR (microbial species)) AND ((community structure) OR (microbiome project) OR (community composition)) AND ((core microbiome)) AND (("2018"[Date - Publication] : "2020"[Date - Publication]))'
# get the updated list of PubMedIDs
entrez <- get_pubmed_ids(CompiledData)
# How many results did the query return?
entrez$Count
# download final list of articles with abstract information
abstracts <- batch_pubmed_download(pubmed_query_string = CompiledData,
dest_file_prefix = "ReferencesLate2020",
format = "medline",
batch_size = 483)
# import the new results to confirm the query worked
FimportCompiledData <- import_results(file = "ReferencesLate202001.txt", verbose = TRUE)
# read the initial .RIS data into R
importRisely <- import_results(file = "ReferencesRisely.ris", verbose = TRUE)
import <- import_results(file = "ReferencesCompiled01.txt", verbose = TRUE) %>%
# join compiled references from R with Risely papers
full_join(importRisely)
# write the new citations to file (anti join takes papers only in the download)
anti_join(FimportCompiledData, import, by = "pubmed_id") %>%
write_bibliography(., "Late2020.bib", format = "bib")
Late2020.bib <- import_results(file = "BibChunks/Late2020.bib", verbose = TRUE)
View(Late2020.bib)
knitr::opts_chunk$set(echo = TRUE)
# run every time
# load required packages
library(litsearchr)
#install.packages("revtools")
library(revtools)
library(tidyverse)
# set working directory to file location
setwd("~/University/University 2020-2021/thesis/MicrobiomeThesis")
# read the initial .RIS data into R
importRisely <- import_results(file = "ReferencesRisely.ris", verbose = TRUE)
import <- import_results(file = "ReferencesCompiled01.txt", verbose = TRUE) %>%
# join compiled references from R with Risely papers
full_join(importRisely)
# this is re-run for every new subset
# this object should have 5 fewer articles than the previous import
importSub <- import_results(file = "BibChunks/download1.bib", verbose = TRUE) %>%
# additional files for import go here, like for initial import above
# make sure NA's are NA's not strings (reads bib format funny)
mutate_all(~ replace(., .=='NA', NA)) %>%
# remove the articles already assessed from the original download
# sorting by title only to streamline the anti_join
anti_join(import, ., by = "title")
# this is the list of articles the next subset is made from
download16.bib <- import_results(file = "BibChunks/download16.bib", verbose = TRUE)
View(download16.bib)
download15.bib <- import_results(file = "BibChunks/download15.bib", verbose = TRUE)
View(download15.bib)
download16.bib <- import_results(file = "BibChunks/download16.bib", verbose = TRUE)
View(download16.bib)
download17.bib <- import_results(file = "BibChunks/download17.bib", verbose = TRUE)
View(download17.bib)
download16.bib <- import_results(file = "BibChunks/download16.bib", verbose = TRUE)
View(download16.bib)
importRiselyLate <- import_results(file = "Late2020.bib", verbose = TRUE)
set <- importLate[sample(nrow(import), 7),]
importLate <- import_results(file = "Late2020.bib", verbose = TRUE)
set <- importLate[sample(nrow(import), 7),]
# writing file called download1 to BibChunks folder (could use better names)
# writing to bib to ensure all info is captured (even columns with NA)
write_bibliography(set, "BibChunks/Late2020.bib", format = "bib")
set <- importLate[sample(nrow(importLate), 7),]
write_bibliography(set, "BibChunks/Late2020.bib", format = "bib")
importSubLate1 <- import_results(file = "BibChunks/Late2020.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importSubLate1, ., by = "title")
set <- importLate[sample(nrow(importLate), 7),]
write_bibliography(set, "BibChunks/Late2020.bib", format = "bib")
importSubLate1 <- import_results(file = "BibChunks/Late2020.bib", verbose = TRUE) %>%
mutate_all(~ replace(., .=='NA', NA)) %>%
anti_join(importLate, ., by = "title")
View(Late2020.bib)
# read the initial .RIS data into R
importRiselyLate <- import_results(file = "Late2020.bib", verbose = TRUE)
importLate <- import_results(file = "Late2020.bib", verbose = TRUE) %>%
# read the initial .RIS data into R
importRiselyLate <- import_results(file = "Late2020.bib", verbose = TRUE)
importLate <- import_results(file = "Late2020.bib", verbose = TRUE) %>%
# read the initial .RIS data into R
importRiselyLate <- import_results(file = "Late2020.bib", verbose = TRUE)
# write query based on searchterms and date parameter
CompiledData <- '(((microbial community) OR (bacterial community) OR (bacterial communities) OR (microbial communities) OR (microbial species)) AND ((community structure) OR (microbiome project) OR (community composition)) AND ((core microbiome)) AND (("2018"[Date - Publication] : "2020"[Date - Publication]))'
# get the updated list of PubMedIDs
entrez <- get_pubmed_ids(CompiledData)
# How many results did the query return?
entrez$Count
# download final list of articles with abstract information
abstracts <- batch_pubmed_download(pubmed_query_string = CompiledData,
dest_file_prefix = "ReferencesLate2020",
format = "medline",
batch_size = 483)
# import the new results to confirm the query worked
FimportCompiledData <- import_results(file = "ReferencesLate202001.txt", verbose = TRUE)
# read the initial .RIS data into R
importRisely <- import_results(file = "ReferencesRisely.ris", verbose = TRUE)
import <- import_results(file = "ReferencesCompiled01.txt", verbose = TRUE) %>%
# join compiled references from R with Risely papers
full_join(importRisely)
# write the new citations to file (anti join takes papers only in the download)
anti_join(FimportCompiledData, import, by = "pubmed_id") %>%
write_bibliography(., "Late2020.bib", format = "bib")
Late2020.bib <- import_results(file = "BibChunks/Late2020.bib", verbose = TRUE)
View(Late2020.bib)
Late2020.bib <- import_results(file = "BibChunks/Late2020.bib", verbose = TRUE)
View(Late2020.bib)
# write the new citations to file (anti join takes papers only in the download)
anti_join(FimportCompiledData, import, by = "pubmed_id") %>%
write_bibliography(., "Late2020.bib", format = "bib")
Late2020.bib <- import_results(file = "BibChunks/Late2020.bib", verbose = TRUE)
View(Late2020.bib)
# read the initial .RIS data into R
importRisely <- import_results(file = "ReferencesRisely.ris", verbose = TRUE)
import <- import_results(file = "ReferencesCompiled01.txt", verbose = TRUE) %>%
# join compiled references from R with Risely papers
full_join(importRisely)
# write the new citations to file (anti join takes papers only in the download)
anti_join(FimportCompiledData, import, by = "pubmed_id") %>%
write_bibliography(., "Late2020.bib", format = "bib")
# read the initial .RIS data into R
importRisely <- import_results(file = "ReferencesRisely.ris", verbose = TRUE)
import <- import_results(file = "ReferencesCompiled01.txt", verbose = TRUE) %>%
# join compiled references from R with Risely papers
full_join(importRisely)
# load required packages
library(easyPubMed)
library(revtools)
library(litsearchr)
library(tidyverse)
# write query based on searchterms and date parameter
CompiledData <- '(((microbial community) OR (bacterial community) OR (bacterial communities) OR (microbial communities) OR (microbial species)) AND ((community structure) OR (microbiome project) OR (community composition)) AND ((core microbiome)) AND (("2018"[Date - Publication] : "2020"[Date - Publication]))'
# get the updated list of PubMedIDs
entrez <- get_pubmed_ids(CompiledData)
# How many results did the query return?
entrez$Count
# download final list of articles with abstract information
abstracts <- batch_pubmed_download(pubmed_query_string = CompiledData,
dest_file_prefix = "ReferencesLate2020",
format = "medline",
batch_size = 483)
# import the new results to confirm the query worked
FimportCompiledData <- import_results(file = "ReferencesLate202001.txt", verbose = TRUE)
# read the initial .RIS data into R
importRisely <- import_results(file = "ReferencesRisely.ris", verbose = TRUE)
import <- import_results(file = "ReferencesCompiled01.txt", verbose = TRUE) %>%
# join compiled references from R with Risely papers
full_join(importRisely)
# write the new citations to file (anti join takes papers only in the download)
anti_join(FimportCompiledData, import, by = "pubmed_id") %>%
write_bibliography(., "Late2020.bib", format = "bib")
View(Late2020.bib)
# write the new citations to file (anti join takes papers only in the download)
anti_join(FimportCompiledData, import, by = "pubmed_id") %>%
write_bibliography(., "Late2020.bib", format = "bib")
Late2020.bib <- import_results(file = "BibChunks/Late2020.bib", verbose = TRUE)
View(Late2020.bib)
View(importSubLate1)
knitr::opts_chunk$set(echo = TRUE)
# load required packages
library(easyPubMed)
library(revtools)
library(litsearchr)
library(tidyverse)
# write query based on searchterms and date parameter
CompiledData <- '(((microbial community) OR (bacterial community) OR (bacterial communities) OR (microbial communities) OR (microbial species)) AND ((community structure) OR (microbiome project) OR (community composition)) AND ((core microbiome)) AND (("2018"[Date - Publication] : "2020"[Date - Publication]))'
# get the updated list of PubMedIDs
entrez <- get_pubmed_ids(CompiledData)
# How many results did the query return?
entrez$Count
# download final list of articles with abstract information
abstracts <- batch_pubmed_download(pubmed_query_string = CompiledData,
dest_file_prefix = "ReferencesLate2020",
format = "medline",
batch_size = 483)
# import the new results to confirm the query worked
FimportCompiledData <- import_results(file = "ReferencesLate202001.txt", verbose = TRUE)
# read the initial .RIS data into R
importRisely <- import_results(file = "ReferencesRisely.ris", verbose = TRUE)
import <- import_results(file = "ReferencesCompiled01.txt", verbose = TRUE) %>%
# join compiled references from R with Risely papers
full_join(importRisely)
# write the new citations to file (anti join takes papers only in the download)
anti_join(FimportCompiledData, import, by = "pubmed_id") %>%
write_bibliography(., "Late2020.bib", format = "bib")
Late2020.bib <- import_results(file = "BibChunks/Late2020.bib", verbose = TRUE)
View(Late2020.bib)
#set working directory and bring in the Excel Sheet
setwd("~/University/University 2020-2021/thesis/MicrobiomeThesis")
library(readxl)
library(tidyverse)
# functions for analysis
chiFilter <- function(c1, c2){
# c1 = first column of interest
# c2 = second column of interest
df1 <- data.frame(c1, c2) %>% na.omit()
tab <- table(df1$c1, df1$c2)
chi <- chisq.test(tab)
return(chi)
}
